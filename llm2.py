# langchain/llm.py
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

load_dotenv()


def llm_rag2(user_input):
    # loader = PyMuPDFLoader()
    # docs = loader.load()
    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    # split_docs = text_splitter.split_documents(docs)
    # embeddings = OpenAIEmbeddings()
    # vectorstore = FAISS.from_documents(documents=split_docs, embedding=embeddings)
    # retriever = vectorstore.as_retriever()

    text = '''
ë‹¤ìŒì€ íŠ¹ì • ì‚¬ìš©ìê°€ ì½ì€ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìš”ì•½ì…ë‹ˆë‹¤. 
ì œê³µëœ ë°ì´í„°ëŠ” ê°ì •, ëŒ€ë¶„ì•¼, ì†Œë¶„ì•¼, ìœ í˜•ì˜ ìˆœì„œë¡œ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
ê°ì •ì€ ê¸°ì‚¬ì˜ ë…¼ì¡°ê°€ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€ ê· í˜•ì ì¸ì§€ì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤.
ëŒ€ë¶„ì•¼ëŠ” ê²½ì œì™€ ì‚¬íšŒ ë¬¸í™”ë¼ëŠ” í° ì¹´í…Œê³ ë¦¬ì´ê³  ì†Œë¶„ì•¼ëŠ” ê·¸ì— ì†í•˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.
ìœ í˜•ì€ ëŒ€ë¶„ì•¼ì™€ ì†Œë¶„ì•¼ë¥¼ í† ëŒ€ë¡œ ê´€ì‹¬ì‚¬ë¥¼ ìœ í˜•í™”í•œ ê²ƒ.
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìë¥¼ ë¶„ì„/ìš”ì•½í•˜ëŠ” ë‚´ìš©ì„ ì‘ì„±í•  ê²ƒ. 

ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ê³ , ë¶„ì„ì ì¸ ì–´ì¡°ë¡œ ì‘ì„±í•˜ë©°, ì´ëª¨í‹°ì½˜ì„ ì¶”ê°€í•˜ì—¬ 6ì¤„ ì´ë‚´ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹**
Address: ECBS from Seoul, South Korea
Date: [2024-11]

Description----------------


[ì†Œë¶„ì•¼]ë¥¼ ì„ íƒí•œ ë‹¹ì‹ ì€ [ìœ í˜•]ì…ë‹ˆë‹¤! 
[ëŒ€ë¶„ì•¼] ë¶„ì•¼ ì¤‘ [ì†Œë¶„ì•¼]ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤! ğŸ˜ŠğŸ’¡
 [ì¶”ê°€ì ì¸ íŠ¹ì§• 1] ğŸŒ± 
 [ì¶”ê°€ì ì¸ íŠ¹ì§• 2] ğŸ“ˆ

**ì£¼ì˜ì‚¬í•­:**

**Description ì„¹ì…˜:**
   - ì²« ë¬¸ì¥ì€ ê³ ì •ëœ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”: [ì†Œë¶„ì•¼]ë¥¼ ì„ íƒí•œ ë‹¹ì‹ ì€ [ìœ í˜•]! ...
   - ì´í›„ ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì‘ì„±í•˜ë˜, í•„ìˆ˜ ìš”ì†Œë¥¼ í¬í•¨í•˜ì„¸ìš”.
   

 **í˜•ì‹ ì¤€ìˆ˜:**
   - ëŒ€ê´„í˜¸([])ëŠ” ì‹¤ì œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±.
   - ë³¸ë¬¸ì€ 120tokenì´í•˜ë¡œ ì‘ì„±í•˜ë ¤ ë…¸ë ¥í•  ê²ƒ
   - ë§ˆì§€ë§‰ ë¬¸ì¥ì€ "ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ì‚¬ë¥¼ ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì„œ í™•ì¸í•´ ë³´ì„¸ìš”!"ë¡œ ê³ ì •í•  ê²ƒ.


    # Question:
    {question}

    # Answer:
    '''
    prompt = PromptTemplate.from_template(text)

    # 7. LLM
    llm2 = ChatOpenAI(model="chatgpt-4o-latest", temperature=0.2, max_tokens=200)
    

    parser = StrOutputParser()
    # 8. Chains
    chain = (
        {'question': RunnablePassthrough()}
        | prompt
        | llm2
        | parser
    )

    ans1 = chain.invoke(user_input)
    return ans1